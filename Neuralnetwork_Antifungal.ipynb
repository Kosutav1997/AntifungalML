{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3767206408.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install torch torchvision torchaudio\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18421    1\n",
      "18422    1\n",
      "18423    0\n",
      "18424    0\n",
      "18425    1\n",
      "Name: Label, Length: 18407, dtype: int64\n",
      "Fold 1/5\n",
      "  Accuracy:    0.9856\n",
      "  Recall:      0.9906 (Sensitivity)\n",
      "  Specificity: 0.9809\n",
      "  F1-score:    0.9853\n",
      "  MCC:         0.9713\n",
      "  AUC:         0.9969\n",
      "Fold 2/5\n",
      "  Accuracy:    0.9859\n",
      "  Recall:      0.9920 (Sensitivity)\n",
      "  Specificity: 0.9796\n",
      "  F1-score:    0.9861\n",
      "  MCC:         0.9718\n",
      "  AUC:         0.9974\n",
      "Fold 3/5\n",
      "  Accuracy:    0.9837\n",
      "  Recall:      0.9876 (Sensitivity)\n",
      "  Specificity: 0.9797\n",
      "  F1-score:    0.9839\n",
      "  MCC:         0.9674\n",
      "  AUC:         0.9970\n",
      "Fold 4/5\n",
      "  Accuracy:    0.9840\n",
      "  Recall:      0.9853 (Sensitivity)\n",
      "  Specificity: 0.9827\n",
      "  F1-score:    0.9840\n",
      "  MCC:         0.9679\n",
      "  AUC:         0.9974\n",
      "Fold 5/5\n",
      "  Accuracy:    0.9880\n",
      "  Recall:      0.9925 (Sensitivity)\n",
      "  Specificity: 0.9835\n",
      "  F1-score:    0.9882\n",
      "  MCC:         0.9761\n",
      "  AUC:         0.9981\n",
      "\n",
      "=== Average Cross-Validated Metrics ===\n",
      "Accuracy    : 0.9854 ± 0.0017\n",
      "Recall      : 0.9896 ± 0.0031\n",
      "Specificity : 0.9813 ± 0.0017\n",
      "F1          : 0.9855 ± 0.0018\n",
      "Mcc         : 0.9709 ± 0.0035\n",
      "Auc         : 0.9974 ± 0.0005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score,\n",
    "    matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# ---- Load Data ----\n",
    "file_path = '/Users/monikapandey/Library/CloudStorage/OneDrive-LouisianaStateUniversity/ML_ANTIFUNGAL/top_30_features_from_mo.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "df = df.dropna()\n",
    "print(df.Label)\n",
    "#df['Label'] = df.Label.astype('int')\n",
    "\n",
    "target_column = 'Label'\n",
    "\n",
    "# Drop SMILES and other non-numeric columns from features\n",
    "#non_numeric = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "features = df.iloc[:,1:-1]\n",
    "targets = df['Label']\n",
    "\n",
    "# ---- PyTorch Dataset ----\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, features, targets, scaler=None, fit_scaler=False):\n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "        if fit_scaler:\n",
    "            self.features = self.scaler.fit_transform(features)\n",
    "        else:\n",
    "            self.features = self.scaler.transform(features)\n",
    "        self.targets = targets.values.astype('float32')\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float32),\n",
    "            'targets': torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# ---- MLP Model ----\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_inputs, 32)\n",
    "        self.hidden2 = nn.Linear(32, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x.view(-1)\n",
    "\n",
    "def train_model(train_dl, model, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_dl:\n",
    "            inputs, targets = batch['features'], batch['targets']\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate_model(test_dl, model):\n",
    "    model.eval()\n",
    "    predictions, actuals, probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:\n",
    "            inputs, targets = batch['features'], batch['targets']\n",
    "            outputs = model(inputs)\n",
    "            probs.extend(outputs.cpu().numpy())\n",
    "            preds = (outputs > 0.5).int().cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(targets.cpu().numpy())\n",
    "    return np.array(predictions), np.array(actuals), np.array(probs)\n",
    "\n",
    "# ---- Cross Validation ----\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(features)):\n",
    "    print(f\"Fold {fold+1}/5\")\n",
    "    train_features, test_features = features.iloc[train_index], features.iloc[test_index]\n",
    "    train_targets, test_targets = targets.iloc[train_index], targets.iloc[test_index]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_dataset = CSVDataset(train_features, train_targets, scaler=scaler, fit_scaler=True)\n",
    "    test_dataset = CSVDataset(test_features, test_targets, scaler=scaler, fit_scaler=False)\n",
    "    \n",
    "    train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "    \n",
    "    n_inputs = train_dl.dataset.features.shape[1]\n",
    "    model = MLP(n_inputs)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_model(train_dl, model, criterion=criterion, optimizer=optimizer, epochs=50)\n",
    "    \n",
    "    preds, actuals, probs = evaluate_model(test_dl, model)\n",
    "    \n",
    "    acc = accuracy_score(actuals, preds)\n",
    "    rec = recall_score(actuals, preds)\n",
    "    prec = precision_score(actuals, preds)\n",
    "    f1 = f1_score(actuals, preds)\n",
    "    mcc = matthews_corrcoef(actuals, preds)\n",
    "    auc = roc_auc_score(actuals, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(actuals, preds).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"  Accuracy:    {acc:.4f}\")\n",
    "    print(f\"  Recall:      {rec:.4f} (Sensitivity)\")\n",
    "    print(f\"  Specificity: {specificity:.4f}\")\n",
    "    print(f\"  F1-score:    {f1:.4f}\")\n",
    "    print(f\"  MCC:         {mcc:.4f}\")\n",
    "    print(f\"  AUC:         {auc:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold+1,\n",
    "        'accuracy': acc,\n",
    "        'recall': rec,\n",
    "        'specificity': specificity,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'auc': auc\n",
    "    })\n",
    "\n",
    "# ---- Summary and Save ----\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Average Cross-Validated Metrics ===\")\n",
    "for metric in ['accuracy', 'recall', 'specificity', 'f1', 'mcc', 'auc']:\n",
    "    print(f\"{metric.capitalize():<12}: {results_df[metric].mean():.4f} ± {results_df[metric].std():.4f}\")\n",
    "\n",
    "results_df.to_csv('mlp_antifungal_cv_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
